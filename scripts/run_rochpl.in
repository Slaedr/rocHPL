#!/usr/bin/env bash
# Author: Noel Chalmers

# set -x #echo on

# #################################################
# helper functions
# #################################################
function display_help()
{
  echo "rocHPL run helper script"
  echo "./run_rochpl "
  echo "    [-P]    Specific MPI grid size: the number of         "
  echo "            rows in MPI grid.                             "
  echo "    [-Q]    Specific MPI grid size: the number of         "
  echo "            columns in MPI grid.                          "
  echo "    [-p]    Specific node-local MPI grid size: the number "
  echo "            of rows in node-local MPI grid. Must evenly   "
  echo "            divide P.                                     "
  echo "    [-q]    Specific node-local MPI grid size: the number "
  echo "            of columns in node-local MPI grid. Must evenly"
  echo "            divide Q.                                     "
  echo "    [-N]    Specific matrix size: the number of           "
  echo "            rows/columns in global matrix.                "
  echo "    [--NB]  Specific panel size: the number of            "
  echo "            rows/columns in panels.                       "
  echo "    [-f]    Specific split fraction: the percentange to   "
  echo "            split the trailing submatrix.                 "
  echo "    [-i]    Input file. When set, all other commnand      "
  echo "            line parameters are ignored, and problem      "
  echo "            parameters are read from input file.          "
  echo "    [-o|--output_file]  Output file. Default: HPL.out     "
  echo "    [--use_mpi_lbcast]  To Use MPI collective for lbcast  "
  echo "    [-h|--help] prints this help message                  "
  echo "    [--version] Print rocHPL version number.              "
}

# This function is helpful for dockerfiles that do not have sudo installed, but the default user is root
# true is a system command that completes successfully, function returns success
# prereq: ${ID} must be defined before calling
supported_distro( )
{
  if [ -z ${ID+foo} ]; then
    printf "supported_distro(): \$ID must be set\n"
    exit 2
  fi

  case "${ID}" in
    ubuntu|centos|rhel|fedora|sles)
        true
        ;;
    *)  printf "This script is currently supported on Ubuntu, CentOS, RHEL, Fedora and SLES\n"
        exit 2
        ;;
  esac
}

# #################################################
# Pre-requisites check
# #################################################
# Exit code 0: alls well
# Exit code 1: problems with getopt
# Exit code 2: problems with supported platforms

# check if getopt command is installed
type getopt > /dev/null
if [[ $? -ne 0 ]]; then
  echo "This script uses getopt to parse arguments; try installing the util-linux package";
  exit 1
fi

# os-release file describes the system
if [[ -e "/etc/os-release" ]]; then
  source /etc/os-release
else
  echo "This script depends on the /etc/os-release file"
  exit 2
fi

# The following function exits script if an unsupported distro is detected
supported_distro

# #################################################
# global variables
# #################################################
# Grab options from CMake config
rocm_dir=@ROCM_PATH@
rocblas_dir=@ROCBLAS_LIB_PATH@
blas_dir=@HPL_BLAS_DIR@
rochpl_bin=@ROCHPL_BIN@

P=1
Q=1
p=-1
q=-1
N=45312
ncols=$N
NB=384
frac=0.6
proc_grid_layout=COLUMN_MAJOR
# By default, 8 cores per node are reserved for system processes
core_spec=8
use_mpi_lbcast=false
use_mpi_allreduce_dmxswp=false
use_mpi_scatterv=false
use_mpi_allgatherv=false
pfact_type=RIGHT_LOOKING
rfact_type=RIGHT_LOOKING
use_l1_transpose=false
rocprof_trace_run=false
hpct_trace_run=false
trace_output_path="."
num_ranks_traced=1
use_repeats=false
nrepeats=20
use_ncols=false
cpu_trsm_work_size=16
nbmin=16

filename=HPL.dat
inputfile=false
outfilename=HPL.out
outputfile=false
cmdrun=false

export LD_LIBRARY_PATH=${rocblas_dir}:${blas_dir}:${rocm_dir}/lib:$LD_LIBRARY_PATH

oversubscribe=true

# #################################################
# Parameter parsing
# #################################################

# check if we have a modern version of getopt that can handle whitespace and long parameters
getopt -T
if [[ $? -eq 4 ]]; then
  GETOPT_PARSE=$(getopt --name "${0}" --longoptions NB:,help,version,process_grid_layout:,output_file:,program:,use_mpi_lbcast,use_mpi_allreduce_dmxswp,use_mpi_scatterv,use_mpi_allgatherv,pfact_type:,rfact_type:,use_l1_transpose,rocprof,hpct,trace_output_path:,num_ranks_traced:,nrepeats:,core_spec:,num_global_cols:,cpu_trsm_work_size:,nbmin: --options hP:Q:p:q:N:i:f:o:S: -- "$@")
else
  echo "Need a new version of getopt"
  exit 1
fi

if [[ $? -ne 0 ]]; then
  echo "getopt invocation failed; could not parse the command line";
  exit 1
fi

eval set -- "${GETOPT_PARSE}"

while true; do
  case "${1}" in
    -h|--help)
        display_help
        exit 0
        ;;
    --version)
        ${rochpl_bin} --version
        exit 0
        ;;
    -P)
        P=${2}
        shift 2 ;;
    -Q)
        Q=${2}
        shift 2 ;;
    -p)
        p=${2}
        shift 2 ;;
    -q)
        q=${2}
        shift 2 ;;
    -N)
        N=${2}
        cmdrun=true
        shift 2 ;;
    --NB)
        NB=${2}
        cmdrun=true
        shift 2 ;;
    --num_global_cols)
        ncols=${2}
        use_ncols=true
        shift 2 ;;
    -f)
        frac=${2}
        shift 2 ;;
    -i)
        filename=${2}
        inputfile=true
        shift 2 ;;
    --process_grid_layout)
        proc_grid_layout=$(echo ${2} | tr '[:lower:]' '[:upper:]')
        shift 2 ;;
    -o|--output_file)
        outfilename=${2}
        outputfile=true
        shift 2 ;;
    --use_mpi_lbcast)
        use_mpi_lbcast=true
        shift ;;
    --use_mpi_allreduce_dmxswp)
        use_mpi_allreduce_dmxswp=true
        shift ;;
    --use_mpi_scatterv)
        use_mpi_scatterv=true
        shift ;;
    --use_mpi_allgatherv)
        use_mpi_allgatherv=true
        shift ;;
    --pfact_type)
        pfact_type=${2}
        shift 2 ;;
    --rfact_type)
        rfact_type=${2}
        shift 2 ;;
    --use_l1_transpose)
        use_l1_transpose=true
        shift ;;
    --rocprof)
        rocprof_trace_run=true
        shift ;;
    --hpct)
        hpct_trace_run=true
        shift ;;
    --trace_output_path)
        trace_output_path=${2}
        shift 2 ;;
    --num_ranks_traced)
        num_ranks_traced=${2}
        shift 2 ;;
    --program)
        rochpl_bin=${2}
        shift 2 ;;
    --nrepeats)
        nrepeats=${2}
        use_repeats=true
        shift 2 ;;
    -S|--core_spec)
        core_spec=${2}
        shift 2 ;;
    --cpu_trsm_work_size)
        cpu_trsm_work_size=${2}
        shift 2 ;;
    --nbmin)
        nbmin=${2}
        shift 2 ;;
    --) shift ; break ;;
    *)  echo "Unexpected command line parameter received; aborting";
        exit 1
        ;;
  esac
done

#if nothing but np and ppn parameters where given, default to running
# with default input file
if [[ "${inputfile}" == false && "${cmdrun}" == false ]]; then
  inputfile=true
fi

np=$(($P*$Q))
if [[ "$np" -lt 1 ]]; then
  echo "Invalid MPI grid parameters; aborting";
  exit 1
fi

#######################################
# Now figure out the CPU core mappings
#######################################

# Get local process numbering
set +u
if [[ -n ${OMPI_COMM_WORLD_LOCAL_RANK+x} ]]; then
  globalRank=$OMPI_COMM_WORLD_RANK
  globalSize=$OMPI_COMM_WORLD_SIZE
  rank=$OMPI_COMM_WORLD_LOCAL_RANK
  size=$OMPI_COMM_WORLD_LOCAL_SIZE
elif [[ -n ${SLURM_LOCALID+x} ]]; then
  globalRank=$SLURM_PROCID
  globalSize=$SLURM_NTASKS
  rank=$SLURM_LOCALID
  size=$SLURM_TASKS_PER_NODE
  #Slurm can return a string like "2(x2),1". Get the first number
  size=$(echo $size | sed -r 's/^([^.]+).*$/\1/; s/^[^0-9]*([0-9]+).*$/\1/')
fi
set -u

#Determing node-local grid size
if [[ "$p" -lt 1 && "$q" -lt 1 ]]; then
  # no node-local grid was specified, pick defaults
  q=$(( (Q<=size) ? Q : size))

  if [[ $((size % q)) -gt 0 ]]; then
    echo "Invalid MPI grid parameters; Unable to form node-local grid; aborting";
    exit 1
  fi

  p=$(( size/q ))

elif [[ "$p" -lt 1 ]]; then
  #q was specified

  if [[ $((size % q)) -gt 0 ]]; then
    echo "Invalid MPI grid parameters; Unable to form node-local grid; aborting";
    exit 1
  fi

  p=$(( size/q ))

elif [[ "$q" -lt 1 ]]; then
  #p was specified

  if [[ $((size % p)) -gt 0 ]]; then
    echo "Invalid MPI grid parameters; Unable to form node-local grid; aborting";
    exit 1
  fi

  q=$(( size/p ))

else
  #Both p and q were specified
  if [[ $size -ne $((p*q)) ]]; then
    echo "Invalid MPI grid parameters; Unable to form node-local grid; aborting";
    exit 1
  fi
fi

# Check that the columns are evenly divided among nodes
if [[ $((P % p)) -gt 0 ]]; then
  echo "Invalid MPI grid parameters; Must have the same number of P rows on every node; aborting";
  exit 1
fi

# Check that the rows are evenly divided among nodes
if [[ $((Q % q)) -gt 0 ]]; then
  echo "Invalid MPI grid parameters; Must have the same number of Q columns on every node; aborting";
  exit 1
fi

# count the number of physical cores on node
num_cpu_cores=$(lscpu | grep "Core(s)" | awk '{print $4}')
num_cpu_sockets=$(lscpu | grep Socket | awk '{print $2}')
total_cpu_cores=$(($num_cpu_cores*$num_cpu_sockets))

# Ranks in different processes rows will take distinct chunks of cores
row_stride=$((total_cpu_cores/p))
col_stride=$((row_stride/q))

myp=$((rank%p))
myq=$((rank/p))

#Although ranks are column-major order, we select GPUs in row-major order on node
mygpu=$((myq+myp*q))

# Try to detect special Bard-peak core mapping
if [[ -n ${HPL_PLATFORM+x} ]]; then
  platform=$HPL_PLATFORM
else
  platform=$(cat /sys/class/dmi/id/product_name)
fi

if [[ "$platform" == "BardPeak" || "$platform" == "HPE_CRAY_EX235A" ]]; then
  # Special core mapping for BardPeak

  # Debug
  # if [[ $globalRank == 0 ]]; then
  #   echo "BardPeak platform detected"
  # fi
  
  num_domains=8

  # Sanity check
  if [[ $size -gt $num_domains ]]; then
    echo "Unsupported number of ranks on BardPeak platform; aborting";
    exit 1
  fi

  # GCD0 cores="48-55"
  # GCD1 cores="56-63"
  # GCD2 cores="16-23"
  # GCD3 cores="24-31"
  # GCD4 cores="0-7"
  # GCD5 cores="8-15"
  # GCD6 cores="32-39"
  # GCD7 cores="40-47"

  if [[ $core_spec -eq 8 ]]; then
      # 1 + the actual root core, for low-noise mode
      if [ $globalRank -eq 0 ]; then
          echo run_rochpl: core spec = 8
      fi
      root_cores=(49 57 17 25 1 9 33 41)
      num_use_cores=(7 7 7 7 7 7 7 7)
  elif [[ $core_spec -eq 0 ]]; then
      if [ $globalRank -eq 0 ]; then
          echo run_rochpl: core spec = 0
      fi
      root_cores=(48 56 16 24 0 8 32 40)
      num_use_cores=(8 8 8 8 8 8 8 8)
  elif [[ $core_spec -eq 1 ]]; then
      if [ $globalRank -eq 0 ]; then
          echo run_rochpl: core spec = 1
      fi
      root_cores=(48 56 16 24 1 8 32 40)
      num_use_cores=(8 8 8 8 7 8 8 8)
  else
      echo "Invalid core-spec ${core_spec}!"
      exit 1
  fi

  root_core=${root_cores[mygpu]}

  # First omp place is the root core
  omp_places="{$root_core}"

  # First assign the CCD
  for i in $(seq $((root_core+1)) $((root_core+num_use_cores[mygpu]-1)))
  do
    omp_places+=",{$i}"
  done
  omp_num_threads=${num_use_cores[mygpu]}

  places="{$root_core-$((root_core+num_use_cores[mygpu]-1))}"

  # Loop through unassigned CCDs
  for c in $(seq $((mygpu+size)) $size 7)
  do
    iroot_core=${root_cores[c]}
    for i in $(seq $((iroot_core)) $((iroot_core+num_use_cores[c]-1)))
    do
      omp_places+=",{$i}"
    done
    omp_num_threads=$((omp_num_threads+num_use_cores[c]))
    places+=",{$iroot_core-$((iroot_core+num_use_cores[c]-1))}"
  done

  if [[ "${oversubscribe}" == true ]]; then
    # Add cores from different columns, without their root cores
    for j in $(seq 0  $((q-1)))
    do
      if [[ "$j" == "$myq" ]]; then
        continue
      fi
      for jj in $(seq 0 $size 7)
      do
        q_gpu=$((jj+j+myp*q))
        q_core=$((root_cores[q_gpu]))
        offset=$(( (q_gpu>=size) ? 0 : 1))
        for i in $(seq $((q_core+offset)) $((q_core+num_use_cores[q_gpu]-1)))
        do
          omp_places+=",{$i}"
        done
        omp_num_threads=$((omp_num_threads+num_use_cores[q_gpu]-offset))
        places+=",{$((q_core+offset))-$((q_core+num_use_cores[q_gpu]-1))}"
      done
    done
  fi

else
  # Default core mapping
  root_core=$((myp*row_stride + myq*col_stride))

  omp_num_threads=${col_stride}
  # First omp place is the root core
  omp_places="{$root_core}"

  # Make contiuguous chunk of cores (to maximize L1/L2 locality)
  for i in $(seq $((root_core+1)) $((root_core+col_stride-1)))
  do
    omp_places+=",{$i}"
  done

  if [[ $col_stride -gt 1 ]]; then
    places="{$root_core-$((root_core+col_stride-1))}"
  else
    places="{$root_core}"
  fi

  if [[ "${oversubscribe}" == true ]]; then
    # Add cores from different columns, without their root cores
    for j in $(seq 0 $((q-1)))
    do
      if [[ "$j" == "$myq" ]]; then
        continue
      fi
      q_core=$((myp*row_stride + j*col_stride))
      for i in $(seq $((q_core+1)) $((q_core+col_stride-1)))
      do
        omp_places+=",{$i}"
      done
      omp_num_threads=$((omp_num_threads+col_stride-1))

      if [[ $col_stride -gt 2 ]]; then
        places+=",{$((q_core+1))-$((q_core+col_stride-1))}"
      elif [[ $col_stride -gt 1 ]]; then
        places+=",{$((q_core+1))}"
      fi

    done
  fi
fi

# Export OpenMP config
export OMP_NUM_THREADS=${omp_num_threads}
export OMP_PLACES=${omp_places}
export OMP_PROC_BIND=true

if [[ $globalRank -lt $size ]]; then
  echo "Node Binding: Process $rank [(p,q)=($myp,$myq)] CPU Cores: $omp_num_threads - $places"
  echo "  OpenMP places: $OMP_PLACES"
fi

rochpl_args="-P ${P} -Q ${Q} -p ${p} -q ${q} -f ${frac} --pfact_type ${pfact_type} --rfact_type ${rfact_type}"
rochpl_args+=" --cpu_trsm_work_size ${cpu_trsm_work_size} --nbmin ${nbmin}"

if [[ "${inputfile}" == true ]]; then
  rochpl_args+=" -i ${filename}"
else
  rochpl_args+=" -N ${N} -NB ${NB}"
fi

if [[ "${outputfile}" == true ]]; then
  rochpl_args+=" -o ${outfilename}"
fi

if [[ "${use_mpi_lbcast}" == true ]]; then
    rochpl_args+=" --use_mpi_lbcast"
fi
if [[ "${use_mpi_allreduce_dmxswp}" == true ]]; then
    rochpl_args+=" --use_mpi_allreduce_dmxswp"
fi
if [[ "${use_mpi_scatterv}" == true ]]; then
    rochpl_args+=" --use_mpi_scatterv"
fi
if [[ "${use_mpi_allgatherv}" == true ]]; then
    rochpl_args+=" --use_mpi_allgatherv"
fi
if [[ "${use_l1_transpose}" == true ]]; then
    rochpl_args+=" --use_l1_transpose"
fi

if [[ "${use_repeats}" == true ]]; then
    rochpl_args+=" --nrepeats ${nrepeats}"
fi
if [[ "${use_ncols}" == true ]]; then
    rochpl_args+=" --num_global_cols ${ncols}"
fi

this_rank_rocprof=false
if [[ "${rocprof_trace_run}" == true ]]; then
    if [[ "${proc_grid_layout}" == ROW_MAJOR ]]; then
        #if [[ $globalRank -eq 0 || $globalRank -eq 1 || $globalRank -eq 2 || $globalRank -eq $((Q-1)) || $globalRank -eq $((Q*p)) ]]; then
        if [[ $globalRank -eq 0 || $globalRank -eq 1 || $globalRank -eq $((Q-1)) || $globalRank -eq $((Q*p)) || $globalRank -eq $((Q*(P-1))) ]]; then
            this_rank_rocprof=true
        fi
    elif [[ "${proc_grid_layout}" == COLUMN_MAJOR ]]; then
        lastnodecol=$((Q/q-1))
        cm_last_col=$((P*lastnodecol+q-1))
        if [[ $globalRank -eq 0 || $globalRank -eq 1 || $globalRank -eq 2 || $globalRank -eq $cm_last_col || $globalRank -eq $size ]]; then
            this_rank_rocprof=true
        fi
    else
        echo "Invalid process grid layout!"
        exit -1
    fi
fi

executor=""
if [[ "${this_rank_rocprof}" == true ]]; then
    executor="rocprof --roctx-trace --hip-trace -d ${trace_output_path}/${SLURM_PROCID} -o ${trace_output_path}/${SLURM_PROCID}/results.csv"
elif [[ "${hpct_trace_run}" == true ]]; then
    executor="hpcrun -o hpctoolkit-measurement-$SLURM_JOB_NAME-$SLURM_JOB_ID -e gpu=amd -e CPUTIME --trace"
fi

#run
${executor} ${rochpl_bin} ${rochpl_args}

# post-process
if [[ "${hpct_trace_run}" == true ]]; then
    hpcstruct hpctoolkit-measurement-$SLURM_JOB_NAME-$SLURM_JOB_ID
    hpcprof -M stats -o hpctoolkit-database-$SLURM_JOB_NAME-$SLURM_JOB_ID hpctoolkit-measurement-$SLURM_JOB_NAME-$SLURM_JOB_ID
fi
